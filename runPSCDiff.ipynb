{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model Training on PSC Bridges2\n",
    "\n",
    "This notebook is adapted to run on PSC's Bridges2 supercomputer.\n",
    "\n",
    "## Prerequisites:\n",
    "1. SSH into Bridges2 via VSCode\n",
    "2. Navigate to `/jet/home/<your_username>`\n",
    "3. Request a GPU node: `interact -p GPU-shared --gres=gpu:v100-32:1 -t 8:00:00 -A cis250019p`\n",
    "4. Load Anaconda: `module load anaconda3`\n",
    "5. Activate your environment (see setup cell below)\n",
    "6. Start Jupyter: `jupyter notebook --no-browser --ip=0.0.0.0`\n",
    "7. Connect to the Jupyter server in VSCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "Run these commands in the terminal BEFORE starting Jupyter:\n",
    "\n",
    "```bash\n",
    "# Create environment (first time only)\n",
    "conda create -n diffusion_env python=3.10 -y\n",
    "conda activate diffusion_env\n",
    "\n",
    "# Install PyTorch with CUDA support\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install other dependencies\n",
    "pip install numpy pillow tqdm wandb ruamel.yaml gdown torchmetrics\n",
    "pip install jupyter ipykernel\n",
    "\n",
    "# Register kernel\n",
    "python -m ipykernel install --user --name diffusion_env --display-name \"Python (diffusion)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Verify Setup and Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current directory and GPU availability\n",
    "!pwd\n",
    "!hostname\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown einops pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Navigate to Your Project Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace <your_username> and <your_repo_name> with your actual values\n",
    "import os\n",
    "\n",
    "# Change to your project directory\n",
    "project_dir = \"/jet/home/<username>/<your_repo_name>\"  # TODO: Update this!\n",
    "os.chdir(project_dir)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Verify project structure\n",
    "print(\"\\nProject files:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download and Convert CIFAR-10 to ImageFolder Format\n",
    "\n",
    "Following the original Colab approach - download CIFAR-10 and convert to ImageFolder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and distribute CIFAR10 data into train and test\n",
    "\"\"\"\n",
    "root = \"./data\"\n",
    "out_root = f\"{root}/cifar10_imagefolder\"\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "print(f\"Data will be saved to: {out_root}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from torchvision.datasets import CIFAR10\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.\n",
    "# Tech Report: https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf\n",
    "# Dataset link (original not torchvision): https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "train_ds = CIFAR10(root=root, train=True,  download=True)\n",
    "test_ds  = CIFAR10(root=root, train=False, download=True)\n",
    "classes = train_ds.classes  # ['airplane','automobile',...,'truck']\n",
    "\n",
    "print(f\"Train samples: {len(train_ds)}\")\n",
    "print(f\"Test samples: {len(test_ds)}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet-100 Download for VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./data\"\n",
    "out_root = f\"{root}/imagenet100_128x128\"\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "print(f\"Data will be saved to: {out_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import tarfile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "root = \"./data\"\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "# Download ImageNet-100 128x128\n",
    "tar_path = f\"{root}/imagenet100_128x128.tar.gz\"\n",
    "extract_path = f\"{root}/imagenet100_128x128\"\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    # Download from Google Drive\n",
    "    if not os.path.exists(tar_path):\n",
    "        print(\"Downloading ImageNet-100 128x128 from Google Drive...\")\n",
    "        url = \"https://drive.google.com/file/d/11Pk4QvNX3fZkpa_ZvdjD_fQFjCBoa1M0/view\"\n",
    "        gdown.download(url, tar_path, quiet=False, fuzzy=True)\n",
    "        print(\"Download complete!\")\n",
    "    \n",
    "    # Extract tar.gz\n",
    "    print(\"Extracting archive...\")\n",
    "    with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "        tar.extractall(root)\n",
    "    print(\"Extraction complete!\")\n",
    "    \n",
    "    # Clean up tar file (optional)\n",
    "    # os.remove(tar_path)\n",
    "else:\n",
    "    print(f\"ImageNet-100 already exists at {extract_path}\")\n",
    "\n",
    "# Check the structure\n",
    "print(\"\\nDataset structure:\")\n",
    "print(f\"Contents of {extract_path}:\")\n",
    "for item in os.listdir(extract_path):\n",
    "    item_path = os.path.join(extract_path, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        num_items = len(os.listdir(item_path))\n",
    "        print(f\"  {item}/  ({num_items} items)\")\n",
    "    else:\n",
    "        print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "\"\"\"\n",
    "# Transforms for 128x128 ImageNet-100\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Load datasets (adjust paths based on actual structure)\n",
    "train_ds = ImageFolder(root=f\"{extract_path}/train\", transform=train_transform)\n",
    "test_ds = ImageFolder(root=f\"{extract_path}/validation\", transform=val_transform)\n",
    "\n",
    "classes = train_ds.classes\n",
    "print(f\"\\nTrain samples: {len(train_ds)}\")\n",
    "print(f\"Test samples: {len(test_ds)}\")\n",
    "print(f\"Number of classes: {len(classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ImageFolder: ./data/cifar10_imagefolder/{train|val}/{class}/img_XXXXX.png\n",
    "\"\"\"\n",
    "def dump_split(ds, split_name):\n",
    "    split_dir = f\"{out_root}/{split_name}\"\n",
    "    if os.path.exists(split_dir):\n",
    "        shutil.rmtree(split_dir)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    # make per-class dirs\n",
    "    for c in classes:\n",
    "        os.makedirs(os.path.join(split_dir, c), exist_ok=True)\n",
    "    # write PNGs\n",
    "    for i in tqdm(range(len(ds)), desc=f\"Writing {split_name} set\"):\n",
    "        img, label = ds[i]                       # PIL Image, int label\n",
    "        cls = classes[label]\n",
    "        img.save(os.path.join(split_dir, cls, f\"img_{i:05d}.png\"))\n",
    "\n",
    "dump_split(train_ds, \"train\")\n",
    "dump_split(test_ds,  \"val\")\n",
    "\n",
    "print(\"\\nDone! Point train.py --data_dir to:\", f\"{out_root}/train\")\n",
    "print(\"Validation dir:\", f\"{out_root}/val\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the structure\n",
    "\"\"\"\n",
    "#for CIFAR10\n",
    "print(\"\\nDirectory structure:\")\n",
    "!ls -lh {out_root}/\n",
    "print(\"\\nTrain classes:\")\n",
    "!ls {out_root}/train/\n",
    "print(\"\\nSample counts per class (train):\")\n",
    "!ls {out_root}/train/airplane/ | wc -l\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4b: Set Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data paths for training\n",
    "data_dir = f\"{out_root}/train\"\n",
    "#val_dir = f\"{out_root}/val\"\n",
    "val_dir = f\"{out_root}/validation\"\n",
    "\n",
    "print(f\"Training data: {data_dir}\")\n",
    "print(f\"Validation data: {val_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure Weights & Biases (W&B)\n",
    "\n",
    "Set up W&B for experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Login to W&B (run this once)\n",
    "# You'll need to paste your API key from https://wandb.ai/authorize\n",
    "#wandb.login()\n",
    "os.environ[\"WANDB_ENTITY\"] = \"Diffusion-F25DL_Project\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"DiffusionRuns\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"<insert-api-key>\"\n",
    "\n",
    "\n",
    "RESUME_LOGGING = False # Set this to true if you are resuming training from a previous run\n",
    "\n",
    "# Create your wandb run\n",
    "#run_name = '{}_checkpoint_submission_1'.format(config['Name'])\n",
    "run_name = '<insert-run-name>'  # TODO: Update this!\n",
    "\n",
    "# If you are resuming an old run\n",
    "\n",
    "\n",
    "wandb.login(key=\"<insert-api-key>\") \n",
    "\n",
    "if RESUME_LOGGING:\n",
    "    run = wandb.init(\n",
    "        id     = \"\", ### Insert specific run id here if you want to resume a previous run\n",
    "        resume = \"must\", ### You need this to resume previous runs\n",
    "        project = \"DiffusionRuns\", ### Project should be created in your wandb\n",
    "        settings = wandb.Settings(_service_wait=300)\n",
    "    )\n",
    "\n",
    "\n",
    "else:\n",
    "    run = wandb.init(\n",
    "        name    = run_name, ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
    "        reinit  = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "        entity=\"Diffusion-F25DL_Project\",\n",
    "        project = \"DiffusionRuns\" ### Project should be created in your wandb account\n",
    "        #config  = config ### Wandb Config for your run\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Check Your Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display your config file\n",
    "config_path = \"configs/ddpm.yaml\"  # TODO: Update if using a different config\n",
    "\n",
    "if os.path.exists(config_path):\n",
    "    print(f\"Config file: {config_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    with open(config_path, 'r') as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(f\"Config file not found: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run Training\n",
    "\n",
    "### Option A: Match Original Colab Command (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to project directory\n",
    "%cd /jet/home/dkilari/F25-Deep-Learning-Project \n",
    "\n",
    "# Training command matching original Colab setup\n",
    "\"\"\"\n",
    "!python train.py \\\n",
    "  --output_dir experiments \\\n",
    "  --data_dir {data_dir} \\\n",
    "  --val_dir {val_dir} \\\n",
    "  --image_size 32 --unet_in_size 32 \\\n",
    "  --num_classes 10 \\\n",
    "  --batch_size 64 --num_workers 8 \\\n",
    "  --num_epochs 50 --learning_rate 1e-4 --weight_decay 1e-4 \\\n",
    "  --num_train_timesteps 1000 --num_inference_steps 50 \\\n",
    "  --beta_start 0.0001 --beta_end 0.02 --beta_schedule linear \\\n",
    "  --use_ddim False --ddim_eta 0.0 \\\n",
    "  --latent_ddpm True \\\n",
    "  --run_name psc_imagenet_vae_no_ddim_1\n",
    "\"\"\"\n",
    "\n",
    "!python train.py \\\n",
    "  --output_dir experiments \\\n",
    "  --data_dir {data_dir} \\\n",
    "  --val_dir {val_dir} \\\n",
    "  --image_size 128 --unet_in_size 32 \\\n",
    "  --num_classes 100 \\\n",
    "  --batch_size 64 \\\n",
    "  --num_workers 4 \\\n",
    "  --num_epochs 100 \\\n",
    "  --unet_ch 160 \\\n",
    "  --unet_ch_mult 1 2 2 3 \\\n",
    "  --unet_attn 1 2 3 \\\n",
    "  --unet_num_res_blocks 2 \\\n",
    "  --unet_dropout 0.1 \\\n",
    "  --learning_rate 2e-4 --weight_decay 1e-5 \\\n",
    "  --num_train_timesteps 1000 --num_inference_steps 100 \\\n",
    "  --beta_start 0.0001 --beta_end 0.02 --beta_schedule linear \\\n",
    "  --latent_ddpm True \\\n",
    "  --use_ddim False --ddim_eta 0.0 \\\n",
    "  --eval_fid_is True \\\n",
    "  --run_name imagenet100_vae_sc_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: With Config File (if you have one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with config file\n",
    "\"\"\"\n",
    "!python train.py \\\n",
    "    --config configs/cifar10.yaml \\\n",
    "    --data_dir {data_dir} \\\n",
    "    --val_dir {val_dir}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: With Classifier-Free Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add CFG for conditional generation\n",
    "\"\"\"\n",
    "!python train.py \\\n",
    "  --data_dir {data_dir} \\\n",
    "  --val_dir {val_dir} \\\n",
    "  --image_size 32 --unet_in_size 32 \\\n",
    "  --num_classes 10 \\\n",
    "  --batch_size 64 --num_workers 4 \\\n",
    "  --num_epochs 50 --learning_rate 1e-4 \\\n",
    "  --num_train_timesteps 1000 --num_inference_steps 50 \\\n",
    "  --beta_start 0.0001 --beta_end 0.02 \\\n",
    "  --use_ddim True --ddim_eta 0.0 \\\n",
    "  --use_cfg True --cfg_guidance_scale 3.0 \\\n",
    "  --run_name psc_cifar10_cfg\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option D: Background Training (For Long Runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in background - useful if your Jupyter session might disconnect\n",
    "# Note: Run this in the terminal, not in Jupyter\n",
    "\n",
    "print(\"To run in background, use this command in the terminal:\")\n",
    "print(f\"\"\"\\nnohup python train.py \\\\\n",
    "  --data_dir {data_dir} \\\\\n",
    "  --val_dir {val_dir} \\\\\n",
    "  --image_size 32 --unet_in_size 32 \\\\\n",
    "  --num_classes 10 \\\\\n",
    "  --batch_size 64 --num_workers 4 \\\\\n",
    "  --num_epochs 50 --learning_rate 1e-4 \\\\\n",
    "  --num_train_timesteps 1000 --num_inference_steps 50 \\\\\n",
    "  --use_ddim True --ddim_eta 0.0 \\\\\n",
    "  > training.log 2>&1 &\n",
    "\n",
    "# Then monitor with:\n",
    "tail -f training.log\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Monitor Training Progress\n",
    "\n",
    "Check your W&B dashboard or view the training log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check experiments directory\n",
    "\"\"\"\n",
    "!ls -lh experiments/\n",
    "\n",
    "# View latest experiment\n",
    "import glob\n",
    "experiments = sorted(glob.glob('experiments/exp-*'))\n",
    "if experiments:\n",
    "    latest_exp = experiments[-1]\n",
    "    print(f\"\\nLatest experiment: {latest_exp}\")\n",
    "    print(\"\\nCheckpoints:\")\n",
    "    !ls -lh {latest_exp}/checkpoints/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: View Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find the latest experiment\n",
    "experiments = sorted(glob.glob('experiments/exp-*'))\n",
    "if experiments:\n",
    "    latest_exp = experiments[-1]\n",
    "    \n",
    "    # Check if there are any generated images saved locally\n",
    "    # (Your training script saves to W&B, but you can add local saving too)\n",
    "    print(f\"Check W&B dashboard for generated images!\")\n",
    "    print(f\"Experiment directory: {latest_exp}\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
